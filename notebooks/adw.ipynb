{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import asyncio\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from dotenv import load_dotenv\n",
    "from collections import deque\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.together import TogetherLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    step,\n",
    "    Workflow,\n",
    "    Event,\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent\n",
    ")\n",
    "from llama_index.readers.whisper import WhisperReader\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str \n",
    "\n",
    "class GenerateQuestionEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    field: str \n",
    "    query: str\n",
    "\n",
    "class ResponseEvent(Event):\n",
    "    field: str \n",
    "    response: str\n",
    "\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobPilotWorkflow(Workflow):\n",
    "\n",
    "    storage_dir = '../storage'\n",
    "    llm: TogetherLLM\n",
    "    query_engine: VectorStoreIndex\n",
    "    \n",
    "    @step \n",
    "    async def setup(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume:\n",
    "            raise ValueError(\"No resume file provided.\") \n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "        \n",
    "        self.llm = TogetherLLM(model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\")\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # read parsed resume from disk\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(\n",
    "                storage_context,\n",
    "                embed_model=HuggingFaceEmbedding(\n",
    "                    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # parse and load resume\n",
    "            documents = LlamaParse(\n",
    "                api_key=os.getenv('LLAMA_CLOUDE_API_KEY'),\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                system_prompt=\"This is a resume/cv, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume)\n",
    "            # embed and index resume\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=HuggingFaceEmbedding(\n",
    "                    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    "                )\n",
    "            )\n",
    "            # store embed and indexed doc to disk\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "        \n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "    \n",
    "    @step \n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionEvent:\n",
    "        # parse and load application form\n",
    "        documents = LlamaParse(\n",
    "            api_key=os.getenv('LLAMA_CLOUDE_API_KEY'),\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            system_prompt=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            system_prompt_append=\"Return a bulleted list of the fields ONLY.\"\n",
    "        ).load_data(ev.application_form)\n",
    "        result = documents[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        # set list of fields to fillout\n",
    "        await ctx.set('fields', fields)\n",
    "\n",
    "        return GenerateQuestionEvent()\n",
    "\n",
    "    @step \n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get list of fields to fillout\n",
    "        fields = await ctx.get('fields')\n",
    "\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            # if incomming even is feedback\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "\n",
    "            ctx.send_event(\n",
    "                QueryEvent(\n",
    "                    field=field,\n",
    "                    query=question\n",
    "                )\n",
    "            )\n",
    "         # store number of total fields\n",
    "        await ctx.set('total_fields', len(fields))\n",
    "\n",
    "        return\n",
    "\n",
    "    @step \n",
    "    async def ask_question(self, cxt: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        \n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume/cv we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "    \n",
    "    @step \n",
    "    async def fill_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent | StopEvent:\n",
    "        \n",
    "        total_fields = await ctx.get('total_fields')\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if not responses:\n",
    "            return None \n",
    "        \n",
    "        # all responses list\n",
    "        responses_list = '\\n'.join(f'Field: {r.field} \\nResponse: {r.response}' for r in responses)\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responses_list}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result form\n",
    "        await ctx.set('filled_form', str(result))\n",
    "\n",
    "        # let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        ) \n",
    "    \n",
    "    @step \n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "        \n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 57042baa-7a4a-4d31-8f46-62a2a720aed9\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the list of fields with succinct, factual answers:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not listed\n",
      "5. **Linkedin**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: \n",
      "   - EcoTrack: A full-stack carbon footprint tracking application using React, Node.js, and MongoDB.\n",
      "   - ChatFlow: A real-time chat application with WebSocket protocol, React, end-to-end encryption, and message persistence.\n",
      "   - Personal portfolio: sarahchen.dev\n",
      "   - GitHub profile: github.com/sarahcodes\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: \n",
      "    - Frontend: React.js, Redux, Next.js, Vue.js, Nuxt.js\n",
      "    - Backend: Node.js, Express.js, Python, Django\n",
      "    - Databases: PostgreSQL, MongoDB\n",
      "    - APIs: GraphQL, REST APIs\n",
      "    - Testing: Jest, React Testing Library\n",
      "    - Tools: WebPack, Babel\n",
      "12. **Describe why you’re a good fit for this position**: \n",
      "    - Seasoned full-stack developer with over 6 years of experience.\n",
      "    - Proven track record in crafting scalable web applications and microservices.\n",
      "    - Proficient in React, Node.js, and cloud architecture.\n",
      "    - Experience in leading technical teams and mentoring junior developers.\n",
      "    - Strong communication skills with a large following on tech blogging platforms.\n",
      "13. **Do you have 5 years of experience in React?**: Yes\n",
      "LLM says the verdict was FEEDBACK\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the list of fields with succinct, factual answers:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not listed\n",
      "5. **Linkedin**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: sarahchen.dev\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: \n",
      "    - Frontend: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS, Jest, React Testing Library, WebPack, Babel\n",
      "    - Backend: Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB\n",
      "    - Tools/Technologies: Docker, Kubernetes, AWS (EC2, S3, Lambda), Git, GitHub Actions, Jenkins, CircleCI\n",
      "    - Methodologies: Agile/Scrum, performance optimization, automated testing, accessibility compliance (WCAG 2.1)\n",
      "12. **Describe why you’re a good fit for this position**: \n",
      "    - Seasoned Full Stack Web Developer with over 6 years of experience\n",
      "    - Proficient in React, Node.js, and cloud architecture\n",
      "    - Proven track record of leading technical teams and implementing CI/CD pipelines\n",
      "    - Experienced in architecting high-traffic applications and microservices\n",
      "    - Holds relevant certifications (AWS, Google Cloud, MongoDB)\n",
      "13. **Do you have 5 years of experience in React?**: Yes\n",
      "\n",
      "Let me know if you'd like me to make any adjustments!\n",
      "LLM says the verdict was FEEDBACK\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "### Application Form Fields with Succinct Answers\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not available\n",
      "5. **Linkedin**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: sarahchen.dev\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB\n",
      "12. **Describe why you’re a good fit for this position**: Seasoned full-stack developer with a proven track record of crafting scalable web applications and microservices, with over 6 years of experience and a strong expertise in technologies like React and Node.js.\n",
      "13. **Do you have 5 years of experience in React?**: Yes\n",
      "\n",
      "### Explanation\n",
      "\n",
      "The provided responses were analyzed and condensed into succinct answers for each field in the application form. For fields like \"Phone,\" where the response indicated that the information was not available in the resume/CV, \"Not available\" was used as the answer. For \"Project Portfolio,\" the URL of the portfolio was extracted from the detailed response. Technical skills were listed out based on the technologies mentioned in the response. The answer to \"Describe why you’re a good fit for this position\" was condensed to highlight the candidate's experience and key strengths. Finally, the determination of having 5 years of experience in React was based on the analysis provided in the response.\n",
      "LLM says the verdict was OKAY\n",
      "### Application Form Fields with Succinct Answers\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not available\n",
      "5. **Linkedin**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: sarahchen.dev\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, Node.js, Express.js, Python, Django, GraphQL, REST APIs, PostgreSQL, MongoDB\n",
      "12. **Describe why you’re a good fit for this position**: Seasoned full-stack developer with a proven track record of crafting scalable web applications and microservices, with over 6 years of experience and a strong expertise in technologies like React and Node.js.\n",
      "13. **Do you have 5 years of experience in React?**: Yes\n",
      "\n",
      "### Explanation\n",
      "\n",
      "The provided responses were analyzed and condensed into succinct answers for each field in the application form. For fields like \"Phone,\" where the response indicated that the information was not available in the resume/CV, \"Not available\" was used as the answer. For \"Project Portfolio,\" the URL of the portfolio was extracted from the detailed response. Technical skills were listed out based on the technologies mentioned in the response. The answer to \"Describe why you’re a good fit for this position\" was condensed to highlight the candidate's experience and key strengths. Finally, the determination of having 5 years of experience in React was based on the analysis provided in the response.\n"
     ]
    }
   ],
   "source": [
    "jobpilot = JobPilotWorkflow(timeout=600, verbose=False)\n",
    "handler = jobpilot.run(\n",
    "    resume='../data/fake_resume.pdf',\n",
    "    application_form='../data/fake_application_form.pdf'\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        print(\"We've filled in your form! Here are the results:\\n\")\n",
    "        print(event.result)\n",
    "        feedback = input(event.prefix)\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=feedback\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
